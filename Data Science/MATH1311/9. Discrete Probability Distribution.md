# Probability Mass Function
We can describe many probabilities at once by expressing the probability as a function
$$P(k)$$
- That takes $k$ as an input and returns the probability
- This is called **Probability Mass Function(Discrete Probability Distribution)**
	- Equation that describes the entire probability space of a [[1. Types of Data#Discrete Data|discrete]](random) variable

## Properties
- Probability for each input must be between 0 and 1
- For all probability mass function, if we sum all the probabilities over all possible $k$'s then it would **add up to 1**
$$P(x=m)+\sum^{}_{k\neq m}P(x=k)= 1$$
$$\therefore P(x=m)=1-\sum^{}_{k\neq m}P(x=k)$$
- We can use complement to easily calculate certain value by [[7. Probability#Negation|negation]] 
$$P(k\geq 2)=1-P(0\text{ or }1)=1-(P(0)+P(1))$$

## Example
- Let there are two dice and integer $k$ is sum of two numbers from rolling each die, what is the probability of getting $k$?
Let $P(k)$ is the probability of getting $k$ if we add two eyes from each die
- $P(k)=\frac{k-1}{36}\text{ } k\in\{2,3,4,5,6,7\}$
- $P(k)=\frac{13-k}{36}\text{ } k\in\{8,9,10,11,12\}$
- $P(k)=0$ otherwise

The sum of the roll of dice discrete because $k$ can only take and integer values

[[Birthday Paradox Example]]

# Binomial Distribution
Given probability of an event $A$ happening once, denoted by $p$, 
$$P(A)=p$$

Binomial Distribution is the probability that **in $n$ events, $A$ happens $k$ times**
- $n$ is called *trials*
- Provided that **each event is independent**

$$B(k;n,p)= _{n}C_{k}\cdot p^{k}(1-p)^{n-k}$$
This can be interpret as an union of $n$ events with $A$ and $\text{not}A$
- ![[Pasted image 20240318202204.png|500]]

This is function of $k$ with domain of $k\in[0,n]$

Notation: $B(k;n,p)$
- `k`: Unknown variable, we can plug in from the *parameter*
- `;`: To separate variable and parameter
- `n & p`: Parameter(Fixed, and given in the context)

# Trinomial Distribution
Extend idea from Binomial distribution to events $A$ and $B$ happening and neither happening
![[Pasted image 20240318211008.png|500]]
$$T(i,j;n, p_{A}, p_{B})=_{n}C_{i}\cdot_{n-i}C_{j}\cdot p_{A}^{i}\cdot p_{B}^{j}\cdot(1-p_{A}-p_{B})^{n-i-j}$$

# Cumulative probabilities
- All probabilities are masses up to certain value
$$C(n)=P(x\leq n)=\sum^{n}_{i=0}P(x=i) $$

# Poisson Distribution
To predict or explain the number of events occurring within a given interval of time or space
- Used to understand **independent events** that occur at a constant rate within a given interval of time
$$P(k)=\frac{\lambda^{k}}{k!}\cdot e^{-\lambda}$$
- Where $\lambda$ is average value, and this is estimating how likely it is that event is happen $k$ times