# Convolutional Neural Network(CNN)
## Architecture
![[Pasted image 20240527124337.png]]

| Hyperparameter        | What does it do?                                                  | Typical values                                                                |
| --------------------- | ----------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| Input Images          | Target images you'd like to discover patterns in                  | Whatever you can take a photo of                                              |
| Input Layers          | Takes in target images and preprocesses them for further layers   | `input_shape = (batch_size, height, width, colour_channels)`                  |
| Convolutional Layers  | Extracts/learns the most importnat features from target images    | Multiple, can create with `tf.keras.layers.ConvXD (X can be multiple values)` |
| Hidden Activation     | Adds non-linearity to learned features                            | Usually [[Activation Functions#ReLU (Rectified Linear Units)\|ReLU]]          |
| Pooling Layer         | Reduces the dimensionality of learned image features              | Average (`tf.keras.layers.AvgPool2D`)or Max(`tf.keras.layers.MaxPool2D`)      |
| Fully Connected Layer | Further refines learned features from convolutional layers        | `tf.keras.layers.Dense`                                                       |
| Output Layer          | Takes learned features and outputs them in shape of target labels | `output_shape=[# images]`                                                     |
| Output Activation     | Adds non-linearities to output layer                              | [[Activation Functions#Sigmoid\|Sigmoid]] or Softmax<br>                      |

## Compare to Normal NN
CNN requires less **trainable parameters** than NN, but still performs better
- Trainable Parameters can be interpreted as *patterns a model can learn from data*
- `NN`: Series of Dense layer with learnable parameters connected to each other -> higher number of possible learnable patterns
- `CNN`: Seeks to sort out and *learn the most important patterns* in an image

# Computer Vision
Practice of writing algorithms which can discover patterns in visual data
- Such as camera of a self-diriving car recognizing the car in front

# Importing & Preprocessing Images
```python
from keras.preprocessing.image import ImageDataGenerator
import zipfile

# Extracting zipfile
archieve = zipfile.ZipFile("folder_path", 'r')
archieve.extractall()
archieve.close()

tf.random.set_seed(42)

# Preprocessing data (Numerical encoding, Normalization)
train_dategen = ImageDataGenerator(rescale=1./255)

train_dir = "train_data folder path"

# importing data from data generator
train_data = train_datagen.flow_from_directory(train_dir,
											  batch_size=32,
											  target_size=(224,224),
											  class_mode="binary",
											  seed=42)
```

# Build a Model
## Convolutional Layer
**Contains the learned weights**, which extract features that distinguish different images from one another

Hyperparameters
1. `Padding`
	- Conserves data at the border of activation maps
	- Preserve the input's spatial size
2. `Kernel Size`
	- Filtering size of the data
	- Smaller kernel size leads to deeper architecture, takes longer
	- larger kernel size leads to poor architecture, takes less; suites for larger features
3. `Strider`
	- Indicates how many pixels the kernel should be shited over at a time
	- Smaller strider let model learn more; leads to larger label layer
	- kernel needs to slide across the input symmetrically

## Pooling Layers
Gradually decreasing spatial extent of the network
- Reduces the parameters and overall computation of the network

Max-Pooling
- *Downsamples the input by taking the maximum value* over the window defined by `pool_size`
- Requires kernel size and stride length selection during design
- Once selected, the operation slides the kernel with the specified stride over the input while only selecting the largest value at each kernel slice from the input to yield a value for the output.

## Flatten Layer
Converts a 3D layer in the network into a 1D vector
- Because [[Activation Functions#Softmax|Softmax]] activation requires 1D vector

# Fit the Model
```python
history = model.fit(train_data,
				   epochs = 'int',
				   steps_per_epoch = len(train_data),
				   validation_data = valid_data,
				   validation_steps=len(valid_data))
```
- `len(data)` = `total # of images / batch_size`

# Evaluate the Model
[[AI & TensorFlow/TensorFlow Bootcamp/3. Neural Network Classification in TF#Classification Evaluation Method|Classification Evaluation]]

## Induce Overfitting
After Creating the baseline, we need to beat it by overfitting a larger model
1. Increase the number of `Conv` layers
2. Increase the number of `Conv` filters
3. Add another dense layer to the output of flattened layer

## Reduce Overfitting(Regularization)
1. Add data argumentation
2. Add regularization layers (such as `MaxPool2D`)
3. Add more data

# Data Argumentation
Process of altering the training data, leading it to have more diversity and in turn allowing our models to learn more generalizable patterns.
- Usually performed on the training data
- This can be done while making training set from `ImageDataGenerator()` by specifying parameters

```python
train_datagen_augmented = ImageDataGenerator(rescale=1/255.,
                                             rotation_range=20, 
                                             shear_range=0.2, 
                                             zoom_range=0.2, 
                                             width_shift_range=0.2,
                                             height_shift_range=0.2, 
                                             horizontal_flip=True) 
```