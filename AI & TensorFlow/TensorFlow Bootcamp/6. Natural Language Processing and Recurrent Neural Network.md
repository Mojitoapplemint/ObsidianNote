# Recurrent Neural Network

| Hyperparameter           | Functionality                                                                             | Typical values                                                                         |
| ------------------------ | ----------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| Input layers             | Takes in target sequence                                                                  | `input_shape`=`[batch_size, embedding_size]` or `[batch_size, sequence_shape]`         |
| Text Vectorization Layer | Maps input sequence to numbers                                                            | `tf.keras.layers.TextVectorization`                                                    |
| Embedding                | Turns mapping of text vectors to embedding matrix(**represeneation of how words relate**) | `tf.keras.layers.Embedding`                                                            |
| RNN cells                | FFind patterns in sequences                                                               | `SimpleRNN`, `LSTM`, `GRU`                                                             |
| Hidden activation        | Adds non-linearity to learned features                                                    | Usually [[Activation Functions#Tanh\|Tanh]]                                            |
| Pooling later            | Reduces the dimensionality of learned sequence features                                   | Global Average Pool, or Max Pool (1D)                                                  |
| Fully connected layer    | Further refines learned features from recurrent layer                                     | Dense layer                                                                            |
| Output layer             | Takes learned featuyres and oiutputs them in shape of target labels                       | `[number_of_classes]`                                                                  |
| Output activation        | Adds non-linearities to output layer                                                      | [[Activation Functions#Sigmoid\|Sigmoid]] or [[Activation Functions#Softmax\|Softmax]] |

# Convert Text into Numerical Form

## Tokenization
Direct mapping from word/character/sub-word to numbers
- Can be modelled but quickly gets too big
- `Sub-Word`: MIxture of word-level and character-level; it breaks individual workds into smaller parts and then convert them into numbers

[`tf.keras.layers.TextVectorization`]([tf.keras.layers.TextVectorization  |  TensorFlow v2.16.1](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization))
- `max_tokens`: Multiples of 10,000 or exact number of unique words in text are common values

## Embedding
Representation of natural language which can be learned
- Returns `feature vector`
- [`tf.keras.layers.Embedding`]([tf.keras.layers.Embedding  |  TensorFlow v2.16.1](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding))