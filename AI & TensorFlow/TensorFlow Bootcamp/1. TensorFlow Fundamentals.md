[Tensorflow API](https://www.tensorflow.org/api_docs/python/tf/random/set_seed)
# What is Tensor?
[Additional Video](https://www.youtube.com/watch?v=f5liqUk0ZTw)
- Some **numerical representation** of information(data)
- Converting information to language that computer can understand
- Including scalar, vector, matrix, n$^{\text{th}}$ dimensional matrix...

# Create Tensors
- `tf.constant()`: Unchangeable Tensor
- `tf.Variable()`: Changeable Tensor
	- **Changeable with `tf.assign()`**
	- `variable[index].assign('new value')`
- `tf.random()`: [[1. TensorFlow Fundamentals#`tf.random` Random Tensors|Random Tensors]]
- `tf.range('int', 'int')`: Create a tensor that contains element from start(inclusive) to end(exclusive)
- `tf.ones()` and `tf.zeros()`
	- Take parameter of  `shape` and generate tensor that contains only 1 or 0
- [[1. TensorFlow Fundamentals#Convert NumPy array into Tensors|Convert NumPy arrays into tensors]]

## Parameters
- `dtype`: Specify the datatype
	- `tf.float16`, etc

# Getting Information from Tensor
## Shape
The length(number of elements) of each of the dimensions of a tensor
- `tensor.shape`

## Rank
The number of tensor dimensions
- `tensor.ndim`
- Scalar : 0
- Vector : 1
- Matrix : 2
- Tensor : n

## Axis and Dimension
A particular dimension of a tensor
- `tensor['index']`

```python
# Get the first 2 elements of each dimension
# Let tensor has shape of (2,3,4,5)

tensor[:2, :2, :2, :2]
=> Will return (2,2,2,2) tensor

# Putting ":" means all of element at that dimension

tensor[:1, :1, :, :1]
=> return (1,1,4,1) tensor
```

## Size
The *total number of items* in the tensor
- `tf.size(tensor)`

## Datatype
- `tensor.dtype`

## Better Print
```python
def tensor_print(tensor):
	print("Datatype of every element:", tensor.dtype) 
	print("Number of dimensions (rank):", tensor.ndim) 
	print("Shape of tensor:", tensor.shape) 
	print("Elements along axis 0 of tensor:",tensor.shape[0]) 
	print("Elements along last axis of tensor:", tensor.shape[-1])
	print("Total number of elements:", tf.size(tensor).numpy()) 
		# .numpy() converts to NumPy array
```

`.numpy()` will get rid of unnecessary information about tensor

# Tensor Operations
## Adding New Dimension

### Using `tf.newaxis`
- Adding new dimension at the end
```python
rank_2_tensor = tf.constant([[1,2],
					    [3,4]])

rank_3_tensor = rank_2_tensor(..., tf.newaxis)
# ...indicates every previous axices

=> rank_3_tensor = [[[1],
				 [2]],
				 
			     [[3],
			      [4]]], shape=(2,2,1)
```

### Using `tf.expand_dims`
- Take one tensor as an input
- Specify `axis` to determine which axis to expand, must be range $[-D, D]$, where $D$ is number of dimension of input
- `axis = -1` is equivalent to `tf.newaxis`

```python
rank_2_tensor = tf.constant([[1,2],
					    [3,4]])

# axis = -1
=> rank_3_tensor = [[[1],
				 [2]],
				 
			     [[3],
			      [4]]], shape=(2,2,1)

# axis = 0
=> rank_3_tensor = [[[1,2],
				 [3,4]]] shape=(1,2,2)

# axis = 1
=> rank_3_tensor = [[[1,2]],
			     
			     [[3,4]]] shape=(2,1,2)
```

## Basic Operations
Basic arithmetic operation is usable **to change each element** of the tensor: `+,-,x,/`
- Element-wise
- `tf.math` functions will be performed faster since it uses GPU

`tf.square(tensor)`
- Squares all element

`tf.math.sqrt(tensor)`
- Takes a square root of all elements
- Requires **floating point** datatype

`tf.math.log(tensor)`
- Computes natural logarithm of all elements
- Requires **floating point** datatype

**Original tensor is unchanged, so we need to assign a new variable**

## Matrix Multiplication
`tf.matmul('tensor_1', 'tensor_2')`

`tf.tensordot('tensor_1','tensor_2', axis=)`

`*` doesn't work for the matrix multiplication
- `@` is python operator of matrix multiplication

## Reshape
We can reshape the tensor using `tf.reshape('tensor', shape)`
- The order of the element is maintained

`tf.transpose` is switching the axes
- Usually use this for matrix multiplication

```python
original_tensor = [[ 7, 8],
			    [ 9,10],
			    [11,12]]

tf.reshape(original_tensor, shape=(2,3))
=> [[ 7, 8, 9],
    [10,11,12]]

tf.transpose(original_tensor)
=> [[ 7, 9, 11],
    [ 8,10, 12]]
```

## Changing the datatype of tensor
Change from `float32` to `float16`
 - Most model use 32 bits datatype, but modern accelerators can run **operations faster in 16 bits**
 - `tf.cast(tensor, dtype = 'datatype')`

# Tensor Aggregation
Condensing them from multiple values down to a smaller amount of values

| Value            | Method                   |
| ---------------- | ------------------------ |
| Absolute Value   | `tf.abs(tensor)`         |
| Maximum          | `tf.reduce_max(tensor)`  |
| Index of maximum | `tf.argmax(tensor)`      |
| Minimum          | `tf.reduce_min(tensor)`  |
| Index of minimum | `tf.argmin(tensor)`      |
| Mean             | `tf.reduce_mean(tensor)` |
| Sum              | `tf.reduce_sum(tensor)`  |

## [[3. Spread and Variance#Variance|Variance]] and [[3. Spread and Variance#Standard Deviation|Standard Deviation]]
`tf.math.reduce_std(tensor)`
- The datatype should be real or complex

`tf.math.reduce_variance(tensor)`
- **Alternative:**
``` python
import tensorflow_probability as tfp

tfp.stats_variance(tensor)
```

## Squeezing the Tensor
Removing all single dimensions(dimension that has only one element)
- `tf.squeeze(tensor)`

# One-Hot Encoding
One way to convert indices into numerical tensors

For example,
- Red = `[1,0,0]`
- Green = `[0,1,0]`
- Blue = `[0,0,1]`

`tf.one_hot(tenor, depth = 'int')`
- Parameter depth is number of element of each row
- We can specify `on_value` and `off_value` parameters to replace 1 and 0

``` python
some_list = [0,1,2,3]
tf.one_hot(some_list, depth = 4)
=> [[1. ,0. ,0. ,0.],
    [0., 1., 0., 0.],
    [0., 0., 1., 0.],
    [0., 0., 0., 1.]]

tf.one_hot(some_list, depth = 4, on_value='true', off_value = 'false')
=> [['true' ,'false' ,'false' ,'false'],
    ['false', 'true', 'false', 'false'],
    ['false', 'false', 'true', 'false'],
    ['false', 'false', 'false', 'true']]
    ```



---
# `tf.random`: Random Tensors
Arbitrary size with random numbers
- Utilize to generate the initial weight(patterns) at the hidden layers and being updated while training
- Specify `shape` to get specific size
- Specify `minval` & `maxval` to restrict the range
- `.normal` to get random tensor from [[5. Normal Distribution|Normal Distribution]]
- `from_seed(int)`: If the seed is same, then the outputs are the same 

```python
random_1 = tf.random.Generator.from_seed(42) # set seed for reducibility
random_1 = random_1.normal(shape=(3,2))
```

### Shuffling elements in Tensor
To shuffle order of inputs so that model can learn various inputs at the same time
- `tf.random.shuffle('tensor')`
- Each row doesn't change
- set `seed` to specify the distribution
- `tf.constant()`also can be shuffled

### Seed
Operations that rely on a random seed actually derive it from:
- **Global Seed:** `tf.random.set_seed('value')`
- **Operation-level seed:** Parameter `seed = 'value'`
- Even though the value is the same, each seed acts differently
- For each seed, if the value is the same, outputs are the same

**Rule 1**: If neither seed is set
- Randomly picked seed is used

**Rule 2**: If only global seed is set
- Picks an operation seed in conjunction with the global seed for unique random sequence
- Sequence doesn't change in the same version of tensorflow and user code

**Rule 3**: If only the operation seed is set
- Uses a default global seed

**Rule 4**: Both seeds are set
- Both seeds are used in conjunction to determine the sequence





# Convert NumPy array into Tensors
The main difference between two is that *tensors can be run on a GPU much faster*
- We can pass numpy array as a parameter of `tf.constant()`
- `shape` can be adjustable to make multi-dimensional tensor
	- The multiplication of all size must be equal to the number of elements
	- If there is no specification, it generates vector

```python
import numpy as np

numpy_A = np.arrange(1,25, dtype = np.int32) # create NumPy array between 1 and 25(exclusively)

A = tf.constant(numpy_A, shape=(2,3,4))

=> A = [[[ 1,  2,  3],
         [ 4,  5,  6],
         [ 7,  8,  9],
         [10, 11, 12]],
 
        [[13, 14, 15],
         [16, 17, 18],
         [19, 20, 21],
         [22, 23, 24]]]

B = tf.constant(numpy_A)
=> B = [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]

# Converting back to numpy array
np.array(B)
B.numpy()
```

However, the default types of them are slightly different when the datatype is floating point value
- Tensor from `np.array` use `float64`
- Normal Tensor use `float32`