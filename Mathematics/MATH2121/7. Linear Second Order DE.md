$$y''+p(x)y'+q(x)y=f(x)$$
- Linear in $y, y', y''$, but not in $x$
- $f(x)$ is called **forcing function**
	- Equation is homogenous if $f=0$
	- Otherwise, it's non-homogenous

For complementary function,
$$y''+p(x)y'+q(x)y=0$$
- $y=0$ is obviously a solution, called trivial solution
- Otherwise, this function satisfies following theorem

# Theorem
Suppose $p$ and $q$ are continuous on an open interval $(a,b)$, let $x_{0}$ be any point in $(a,b)$, and let $k_{0}$ and $k_{1}$ be arbitrary real numbers. Then the initial value problem
$$y''+p(x)y'+q(x)y=f(x)\text{ , } y(x_{0})=k_{0} \text{ , } y'(x_{0})=k_{1}$$
has a unique solution on $(a,b)$

**Right now, rather than finding the answer,  we will focus on verifying the solution**

# General Solution
Let $y_{1}$ and $y_{2}$ are the solutions of homogenous equation
$$y''+p(x)y'+q(x)y=0$$

If $y_{1}$ and $y_{2}$ are defined on an interval $(a,b)$ and $c_{1}$ and $c_{2}$ are constant, then linear combination of $y_{1}$ and $y_{2}$
$$y=c_{1}y_{1}+c_{2}y_{2}$$
is also the solution of the homogenous system on $(a,b)$, called **general solution**

**Proof)**
1. Drive $y'$ and $y''$ from $y=c_{1}y_{1}+c_{2}y_{2}$
2. Substitute them in $y''+p(x)y'+q(x)y$
3. Since $y_{1}$ and $y_{2}$ are the solution, process 2 leads to 0

## Fundamental Set of Solutions
We call $y_{1}$ and $y_{2}$ are linearly independent if they are not multiple to each other

Suppose $p$ and $q$ are continuous on $(a,b)$. Then a set $\{y_{1},y_{2}\}$ of solutions of
$$y''+p(x)y'+q(x)y=0$$
on $(a,b)$ is a **fundamental set** iff $\{y_{1},y_{2}\}$ is linearly independent on $(a,b)$

# Cramer's Rule
For Linear System
$$a_{1}c_{1}+a_{2}c_{2}=k_{0}$$
$$a_{3}c_{1}+a_{4}c_{2} = k_{1}$$
$$c_{1}=\frac{\begin{vmatrix}
k_{0}&a_{2} \\
k_{1}&a_{4}
\end{vmatrix}}{\begin{vmatrix}
a_{1}&a_{2} \\
a_{3}&a_{4}
\end{vmatrix}}=\frac{k_{0}\cdot a_{4}-k_{1}\cdot a_{2}}{a_{1}\cdot a_{4}-a_{2}\cdot a_{3}}$$
$$c_{2}=\frac{\begin{vmatrix}
a_{1}&k_{0} \\
a_{3}&k_{1}
\end{vmatrix}}{\begin{vmatrix}
a_{1}&a_{2} \\
a_{3}&a_{4}
\end{vmatrix}}=\frac{k_{1}\cdot a_{1}-k_{0}\cdot a_{3}}{a_{1}\cdot a_{4}-a_{2}\cdot a_{3}}$$

Using Cramer's Rule, consider Initial value problem
$$y''+p(x)y'+q(x)y=f(x)\text{ , } y(x_{0})=k_{0} \text{ , } y'(x_{0})=k_{1}$$
and its general solution
$$y=c_{1}y_{1}+c_{2}y_{2}$$
From Initial Condition, 
$$k_{0} = c_{1}\cdot y_{1}(x_{0})+c_{2}\cdot y_{2}(x_{0})$$
$$k_{1} = c_{1}\cdot y_{1}'(x_{0})+c_{2}\cdot y_{2}'(x_{0})$$
$$c_{1}=\frac{\begin{vmatrix}
k_{0}&y_{2}(x_{0}) \\
k_{1}&y_{2}'(x_{0})
\end{vmatrix}}{\begin{vmatrix}
y_{1}(x_{0})&y_{2}(x_{0}) \\
y_{1}'(x_{0})&y_{2}'(x_{0})
\end{vmatrix}}=\frac{k_{0}\cdot y_{2}'(x_{0})-k_{1}\cdot y_{2}(x_{0})}{y_{1}(x_{0})\cdot y_{2}'(x_{0})-y_{2}(x_{0})\cdot y_{1}'(x_{0})}$$
$$c_{2}=\frac{\begin{vmatrix}
y_{1}(x_{0})&k_{0} \\
y_{1}'(x_{0})&k_{1}
\end{vmatrix}}{\begin{vmatrix}
y_{1}(x_{0})&y_{2}(x_{0}) \\
y_{1}'(x_{0})&y_{2}'(x_{0})
\end{vmatrix}}=\frac{k_{1}\cdot y_{1}(x_{0})-k_{0}\cdot y_{1}'(x_{0})}{y_{1}(x_{0})\cdot y_{2}'(x_{0})-y_{2}(x_{0})\cdot y_{1}'(x_{0})}$$

**Note)** This works only if $y_{1}(x_{0})\cdot y_{2}'(x_{0})-y_{2}(x_{0})\cdot y_{1}'(x_{0})\neq 0$

## Example
Solve Following:
1. Verify solution
2. Can $y_{1}$ solve this by itself?
3. What $ICs$ would allow $y_{2}$ to solve this by itself?
4. Cramer's Rule

$$y''-y=0$$
Verify $y=c_{1}e^{x}+c_{2}e^{-x}$ is a solution
$y'=c_{1}e^{x}-c_{2}e^{-x}$
$y''=c_{1}e^{x}+c_{2}e^{-x}$
$\implies y''-y=(c_{1}e^{x}+c_{2}e^{-x})-(c_{1}e^{x}+c_{2}e^{-x})=0$

Let $y_{1}=c_{1}e^{x}$, $y_{2}=c_{2}e^{-x}$ and $y(0)=1$, $y'(0)=3$
1) Can $y_{1}$ solve this on its own?
2) For what $ICs$ could $y_{2}$ solve this on its own?

1)
$y_{1}=c_{1}e^{x} \implies y_{1}(0)=c_{1}=1$
$y_{1}'=c_{1}e^{x} \implies y_{1}'(0)=c_{1}=3$
- Doesn't Work

2)
$y_{2}=c_{2}e^{-x}, y_{2}'=-c_{2}e^{-x}\implies y_{1}(0)=c_{2},y'(0)=-c_{2}$
- $y_{2}(0)$ and $y_{2}'(0)$ should be negative to each other

Solution
$y(0)=c_{1}+c_{2}=1$
$y'(0)=c_{1}-c_{2}=3$

According to Cramer's Rule,
$$c_{1}=\frac{\begin{vmatrix}
1&1 \\
3&-1
\end{vmatrix}}{\begin{vmatrix}
1&1 \\
1&-1
\end{vmatrix}}=\frac{-1-3}{-1-1}=2$$
$$c_{2}=\frac{\begin{vmatrix}
1&1 \\
1&3
\end{vmatrix}}{\begin{vmatrix}
1&1 \\
1&-1
\end{vmatrix}}=\frac{3-1}{-1-1}=-1$$
Thus, $y=2e^{x}-e^{-x}$

# Wronskian and Abel's Formula
Suppose $p$ and $q$ are continuous on $(a,b)$. Let $y_{1}$ and $y_{2}$ are the solutions of
$$y''+p(x)y'+q(x)y=0$$
on $(a,b)$. Define
$$W = y_{1}y_{2}'-y_{1}'y_{2}$$
is called **Wronskian** of $\{y_{1}, y_{2}\}$

and let $x_{0}$ be any point in $(a,b)$, then$$W(x) = W(x_{0})e^{-\int^{x}_{x_{0}} p(t) \, dt} \text{, }a<x<b$$
is called **Abel's Formula**
- Either $W$ has no zeros in $(a,b)$ or $W\equiv 0$ on $(a,b)$

## Proof
Differentiating $W$ gives
$$W' = y_{1}'y_{2}'+y_{1}y_{2}''-y_{1}'y_{2}'-y_{1}''y_{2}=y_{1}y_{2}''-y_{1}''y_{2}$$

Since $y_{1}$ and $y_{2}$ are the solution of the homogenous equation, 
$$y_{1}''+p(x)y_{1}'+q(x)y_{1}=0$$
$$y_{2}''+p(x)y_{2}'+q(x)y_{2}=0$$
Multiplying $y_{2}$ in first equation and $y_{2}$ in the second equation yields
$$y_{1}''\cdot y_{2}+p(x)y_{1}'\cdot y_{2}+q(x)y_{1}\cdot y_{2}=0$$
$$y_{2}''\cdot y_{1}+p(x)y_{2}'\cdot y_{1}+q(x)y_{2}\cdot y_{1}=0$$
Subtract two equation yields
$$y_{1}''\cdot y_{2}-y_{2}''\cdot y_{1}+p(x)(y_{1}'\cdot y_{2}-y_{2}'\cdot y_{1})=0$$
Since $W = y_{1}y_{2}'-y_{1}'y_{2}$ and $W' =y_{1}y_{2}''-y_{1}''y_{2}$
$$-W'+p(x)(-W)=0 \implies W'=-p(x)W$$
Which is [[1. Ordinary Differential Equation#Homogenous Equation|Linear first order homogenous equation]]

$$\frac{dW}{dx}=-p(x)W \implies\frac{1}{W}dW = -p(x)dx$$
$$\int^{W}_{W_{0}} \frac{1}{s} \, ds = -\int_{x}^{x_{0}} p(x) \, dx $$
$$\ln W-\ln W_{0} = -\int_{x}^{x_{0}} p(x) \, dx $$
$$W=e^{\ln W_{0}-\int_{x}^{x_{0}} p(x) \, dx }$$
$$\therefore W=W_{0}e^{-\int_{x}^{x_{0}} p(x) \, dx }=W(x_{0})e^{-\int_{x}^{x_{0}} p(x) \, dx }$$



## Wronskian
- Usually written as determinant of the matrix
$$\begin{vmatrix}
y_{1}&y_{2} \\
y_{1}'&y_{2}'
\end{vmatrix}$$
- Using this we can express $c_{1}$ and $c_{2}$ as 
$$c_{1}=\frac{k_{0}\cdot y_{2}'(x_{0})-k_{1}\cdot y_{2}(x_{0})}{y_{1}(x_{0})\cdot y_{2}'(x_{0})-y_{2}(x_{0})\cdot y_{1}'(x_{0})}=\frac{1}{W(x_{0})} \begin{vmatrix}
k_{0}&y_{2}(x_{0}) \\
k_{1}&y_{2}'(x_{0})
\end{vmatrix}$$
$$c_{1}=\frac{k_{1}\cdot y_{1}(x_{0})-k_{0}\cdot y_{1}'(x_{0})}{y_{1}(x_{0})\cdot y_{2}'(x_{0})-y_{2}(x_{0})\cdot y_{1}'(x_{0})} =\frac{1}{W(x_{0})}\begin{vmatrix}
y_{1}(x_{0})&k_{0} \\
y_{1}'(x_{0})&k_{1}
\end{vmatrix}$$

**Note:** $y_{1}$ and $y_{2}$ are linearly independent iff $W$ has no zeros on $W$

# Summary
Suppose $p$ and $q$ are continuous on $(a,b)$. Let $y_{1}$ and $y_{2}$ are the solutions of
$$y''+p(x)y'+q(x)y=0$$
on $(a,b)$. Then the following statements are all equivalent
1. General Solution of equation on $(a,b)$ is $y=c_{1}y_{1}+c_{2}y_{2}$
2. $\{y_{1},y_{2}\}$ is a fundamental set of solutions of the equation on $(a,b)$
3. $\{y_{1},y_{2}\}$ is linearly independent
4. The Wronskian of $\{y_{1},y_{2}\}$ is nonzero at some point in $(a,b)$
5. The Wronskian of $\{y_{1},y_{2}\}$ is nonzero at all points in $(a,b)$