Matrix Decompositions are ways of writing down a matrix as a product of matrices, such as diagonalization

If $A\in \mathcal{M}_{n}(\mathbb{F})$ then the following are equivalent
- $\exists \text{ }P,D\in \mathcal{M}_{n}(\mathbb{F})$ s.t $A=PDP^{-1}$ where $P$ is invertible and $D$ is diagonal
- There is a basis of $\mathbb{F}^{n}$ consisting of eigenvectors of $A$

Q) How close to diagonal can $D$ be if we require that $P$ is unitary?

# Theorem 7.1 Schur Triangularization
Suppose $A \in M_n(\mathbb{C})$. Then there exists a unitary matrix $U \in M_n(\mathbb{C})$ and an upper triangular matrix $T \in M_n(\mathbb{C})$ such that  
$$A = U T U^*$$

**Proof)** 
Proof by induction on the size of $A$

For the base case, we simply notice that the result is trivial if $n = 1$: every $1 \times 1$ matrix is upper triangular.

Assume that theorem is true for matrices in $M_{n-1}(\mathbb{C})$. 
Let $A \in M_n(\mathbb{C})$, and let $\lambda \in \mathbb{C}$ and $\vec{v} \in \mathbb{C}^n$ be an eigenvalue/vector pair 
- (i.e., $Aa = \lambda a$) with $\|\vec{v}\| = 1$.

Let $U = [\vec{v} \mid V]$ for some $V \in M_{n,n-1}(\mathbb{C})$ that makes $U$ unitary.
- We can apply Gram-Schmidt to find $V$
- This means that $\vec{v}$ and all column vectors in $V$ are orthogonal

Let's compute $U^*AU$:

$U^*AU = [\vec{v} \mid V]^*A[\vec{v} \mid V] = \begin{bmatrix}\vec{v}^* \\V^*\end{bmatrix}A\,[\vec{v} \mid V]$

$= \begin{bmatrix}\vec{v}^* \\V^*\end{bmatrix}[A\vec{v} \mid AV] = \begin{bmatrix}\vec{v}^*A\vec{v} & \vec{v}^*AV \\V^*A\vec{v} & V^*AV\end{bmatrix}$
- Each entry is block matrix multiplication
- Consider bottom-left entry
	- $A\vec{v} = \lambda \vec{v}$
	- Then, $\lambda V^{*}\vec{v}$
	- Each entry of $V^{*}\vec{v}$ is a dot product of row vectors of $V^{*}$(column vectors of $V$). Since $V$'s column vectors are orthogonal to $\vec{v}$, each entry will be zero
	- $\therefore V^{*}\vec{v}=\vec{0}$

$= \begin{bmatrix}\lambda\vec{v}^*\vec{v} &\vec{v}^*AV \\\vec{0} & V^*AV\end{bmatrix}$

$=\begin{bmatrix} *&*&*&\dots&*\\0&*&*&\dots&* \\ \vdots & \vdots&\vdots&\ddots&\vdots \\ 0&*&*&\dots&*\end{bmatrix}$

Consider $V^{*}AV\in \mathcal{M}_{n-1}(\mathbb{C})$
- By inductive hypothesis, there exists $U_{2}$ and $T_{2}$ such that
$$V^{*}AV=U_{2}T_{2}U_{2}^{*}$$
where $U_{2}$ is unitary and $T_{2}$ is upper triangle.

Then, Consider $\left(U\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}\right)^{*} A \left(U\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}\right)$
- $\left(U\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}\right)$ is unitary since $U$ and $\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}$ are all unitary

$=\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}^{*}U^{*} A U\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}$

$=\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}^{*}\begin{bmatrix}\lambda\vec{v}^*\vec{v} &\vec{v}^*AV \\\vec{0} & V^*AV\end{bmatrix}\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}$

$=\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}^{*}\end{bmatrix}\begin{bmatrix}\lambda\vec{v}^*\vec{v} &\vec{v}^*AV \\\vec{0} & V^*AV\end{bmatrix}\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}$

$=\begin{bmatrix}\lambda\vec{v}^*\vec{v} &\vec{v}^*AVU_{2} \\\vec{0} & U_{2}^{*}V^*AVU_{2}\end{bmatrix}$

$=\begin{bmatrix}\lambda\vec{v}^*\vec{v} &\vec{v}^*AVU_{2} \\\vec{0} & T_{2}\end{bmatrix}$

Since $T_{2}$ is upper triangle, we've found some upper triangular matrix

$\left(U\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}\right)^{*} A \left(U\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}\right)=\begin{bmatrix}\lambda\vec{v}^*\vec{v} &\vec{v}^*AVU_{2} \\\vec{0} & T_{2}\end{bmatrix}$

$\therefore A=\left(U\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}\right)\begin{bmatrix}\lambda\vec{v}^*\vec{v} &\vec{v}^*AVU_{2} \\\vec{0} & T_{2}\end{bmatrix}\left(U\begin{bmatrix}1& \vec{0}^{*\\}\\\vec{0}& U_{2}\end{bmatrix}\right)^{*}$

# Characteristic of Schur triangularization
## 1. Diagonal entries of $T$ are the eigenvalues of $A$
Recall that the eigenvalues of triangular matrix are its diagonal entries

Consider characteristic polynomial of $A$ : $P_{A}(\lambda)=\det(A-\lambda I)$

$=\det(UTU^{*}-\lambda I)=\det(UTU^{*}-U\lambda IU^{*})=\det(U(T-\lambda I)U^{*})$

$=\det(U)\det(T-\lambda I)\det(U^{*})$

Since $\det(U^{*})=\frac{1}{\det(U)}$, $=\det(T-\lambda I)=P_{T}(\lambda)$

Therefore, eigenvalues of $A$ are eigenvalues of $T$, which are the diagonal entries of $T$

## 2. Not Unique
Entries in $U$ and the strictly upper-triangular entries in $T$ have lots of freedom

# Theorem 7.2 Trace and Determinant in Terms of Eigenvalues
Suppose $A \in M_n(\mathbb{C})$ has eigenvalues $\lambda_1, \lambda_2, \ldots, \lambda_n$. Then  
$$\det(A) = \lambda_1 \lambda_2 \cdots \lambda_n \quad \text{and} \quad \text{tr}(A) = \lambda_1 + \lambda_2 + \cdots + \lambda_n.$$

**Proof)**
Since the diagonal entries of $T$ are $\lambda_1, \lambda_2, \ldots, \lambda_n,$

i) Consider $\det(A)$
$\det(A) = \det(UTU^*) = \det(U)\det(T)\det(U^*)=\det(T)$
- Determinant is multiplicative

Since $T$ is triangular, $= \lambda_1 \lambda_2 \cdots \lambda_n$

ii) Consider $\text{tr}(A)$
$\text{tr}(A) = \text{tr}(UTU^*) = \text{tr}(U^*UT) = \text{tr}(T) = \lambda_1 + \lambda_2 + \cdots + \lambda_n$

# Caley-Hamilton Theorem
Suppose $A\in \mathcal{M}_{n}(\mathbb{C})$ has a characteristic polynomial $p(\lambda)=\det(A-\lambda I)$. Then, $p(A)=O$

**Proof)**
By Fundamental Theorem of Algebra, we can factor characteristic polynomial as a product of linear terms

$p(\lambda) = (\lambda_1 - \lambda)(\lambda_2 - \lambda) \cdots (\lambda_n - \lambda)$

$\text{C-H} \quad \text{says} \quad p(A) = (\lambda_1 I - A)(\lambda_2 I - A) \cdots (\lambda_n I - A) = 0$

Well, let's Schur triangularize $A$:

$A = UTU^*$, then

$p(A) = (\lambda_1 I - UTU^*) (\lambda_2 I - UTU^*) \cdots (\lambda_n I - UTU^*)$

$= U(\lambda_1 I - T) U^* U(\lambda_2 I - T) U^* \cdots U(\lambda_n I - T) U^*$

$= U(\lambda_1 I - T) (\lambda_2 I - T) \cdots (\lambda_n I - T) U^*$

$=U\,p(T)\,U^{*}$

**Goal:** Show that $p(T)$ is 0

$T = \begin{bmatrix} \lambda_1 & * & * & * \\ 0 & \lambda_2 & * & * \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \lambda_n & * \end{bmatrix}$
so $\lambda_1 I - T = \begin{bmatrix} 0 & * & * & * \\ 0 & \lambda_1 - \lambda_2 & * & * \\ 0 & 0 & \lambda_1 - \lambda_3 & * \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \lambda_1 - \lambda_n \end{bmatrix}$
$\lambda_2 I - T = \begin{bmatrix} \lambda_2 - \lambda_1 & * & * & * \\ 0 & 0 & * & * \\ 0 & 0 & \lambda_2 - \lambda_3 & * \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \lambda_2 - \lambda_n \end{bmatrix}$

Claim: 
- $(\lambda_{1}I-T)(\lambda_{2}I-T)$ has first 2 columns $\vec{0}$
- $(\lambda_{k}I-T)(\lambda_{k}I-T)$ has first $k$ columns $\vec{0}$
- So, $(\lambda_{n}I-T)(\lambda_{n}I-T)=O$ 

$p(T)=(\lambda_1 I - T) (\lambda_2 I - T) \cdots (\lambda_n I - T)$

$=\begin{bmatrix} 0&*&*&\dots&*\\0&*&*&\dots&* \\ \vdots & \vdots&\vdots&\ddots&\vdots \\ 0&*&*&\dots&*\end{bmatrix}\begin{bmatrix} *&*&*&\dots&*\\0&0&*&\dots&* \\ \vdots & \vdots&\vdots&\ddots&\vdots \\ 0&*&*&\dots&*\end{bmatrix}\dots\begin{bmatrix} *&*&*&\dots&*\\0&*&*&\dots&* \\ \vdots & \vdots&\vdots&\ddots&\vdots \\ 0&*&*&\dots&0\end{bmatrix}$

$=\begin{bmatrix} 0&0&*&\dots&*\\0&0&*&\dots&* \\ \vdots & \vdots&\vdots&\ddots&\vdots \\ 0&*&*&\dots&*\end{bmatrix}\dots\begin{bmatrix} *&*&*&\dots&*\\0&*&*&\dots&* \\ \vdots & \vdots&\vdots&\ddots&\vdots \\ 0&*&*&\dots&0\end{bmatrix}$

$\dots =O$

## Express $A^{n}$ as a linear combination of $\{ I, A\dots A^{n-1} \}$
$\text{span}(I,A,A^{2}\dots A^{n})$ has dimension that is $\le n$

**Ex)**
Use the Cayley–Hamilton theorem to come up with a formula for $A^4$ as a linear combination of $A$ and $I$, where  $A = \begin{bmatrix} 5 & 9 \\ 2 & -8 \end{bmatrix}$

$\rho(\lambda) = \det(A - \lambda I) = \det\left( \begin{bmatrix} 5 - \lambda & 9 \\ 2 & -8 - \lambda \end{bmatrix} \right) = (5 - \lambda)(-8 - \lambda) - 18 = \lambda^2 + 3\lambda - 58$
C-H says  
$A^2 + 3A - 58I = 0$
- $A^2 = 58I - 3A$  

Then,
$\Rightarrow \quad A^3 = 58A - 3A^2 = 58A - 3(58I - 3A)= -174I + 67A$  
$\Rightarrow \quad A^4 = -174A + 67A^2 = -174A + 67(58I - 3A)= 67 \cdot 58I - 375A$

Use the Cayley–Hamilton theorem to find the inverse of the same matrix.
- Recall that inverse of the matrix has the power of -1

From above  
$A^2 + 3A - 58I = 0$  
$\Rightarrow A^2 + 3A = 58I$  
$\Rightarrow \frac{1}{58}(A^2 + 3A) = I$  
$\Rightarrow A\left(\frac{1}{58}(A + 3I)\right) = I$  
$\therefore A^{-1}=\frac{1}{58}(A+3I)$

# Normal Matrices and Spectral Decomposition
## Normal Matrix
A matrix $A\in \mathcal{M}_{n}(\mathbb{C})$ is called normal if $A^{*}A=A^{*}A$

Ex)
- Unitary
	- If $A^{*}A=I$, then $AA^{*}=I$ by characteristics of unitary
- Hermitian
	- If $A^{*}=A$, then $A^{*}A=AA^{*}=A^{2}$
- Skew-Hermitian
	- If $A^{*}=-A$, then $A^{*}A=AA^{*}=-A^{2}$
- Diagonal
	- If $A=\begin{bmatrix}c_{1}&0&\dots&0\\0&c_{2}&\dots&0\\ \vdots&\vdots&\ddots&\vdots\\0&0&\dots&c_{n}\\\end{bmatrix}$, then $A^{*}A=AA^{*}=A=\begin{bmatrix}|c_{1}|^{2}&0&\dots&0\\0&|c_{2}|^{2}&\dots&0\\ \vdots&\vdots&\ddots&\vdots\\0&0&\dots&|c_{n}|^{2}\\\end{bmatrix}$

## Theorem 7.4 Complex Spectral Decomposition
Suppose $A \in M_n(\mathbb{C})$. Then there exists a unitary matrix $U \in M_n(\mathbb{C})$ and a diagonal matrix $D \in M_n(\mathbb{C})$ such that
$$A = UDU^*$$
iff $A$ is normal.

$(\Leftarrow)$ 
Suppose $A=UDU^{*}$

$A^*A = (UDU^*)^*(UDU^*) = UD^*U^*UDU^* = UD^*DU^*$ and  
$AA^* = (UDU^*)(UDU^*)^* = UDU^*UD^*U^* = UDD^*U^*$

Since $D$ is diagonal, $DD^* = D^*D$, so $A^*A = AA^*$
- $A$ is normal

$(\Rightarrow)$
Suppose $A$ is normal

By Schur Triangularization, $A=UTU^{*}$ for some unitary $U$ and triangular $T$

$A^{*}A=(UTU^*)^*(UTU^*) = UT^*U^*UTU^* = UT^*TU^*$
$AA^* = (UTU^*)(UTU^*)^* = UTU^*UT^*U^* = UTT^*U^*$

Since $A$ is normal, $UT^{*}TU^{*}=UTT^{*}U^{*}$
- $T^{*}T=TT^{*}$, $T$ is also normal

Let $T=$

$T = \begin{bmatrix} t_{1,1} & t_{1,2} & \cdots & t_{1,n} \\ 0 & t_{2,2} & \cdots & t_{2,n} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & t_{n,n} \end{bmatrix}$

$T^{*}T = \begin{bmatrix} \overline{t_{1,1}} & 0 & \cdots & 0 \\ \overline{t_{1,2}} & \overline{t_{2,2}} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ \overline{t_{1,n}} & \overline{t_{2,n}} & \cdots & \overline{t_{n,n}} \end{bmatrix} \begin{bmatrix} t_{1,1} & t_{1,2} & \cdots & t_{1,n} \\ 0 & t_{2,2} & \cdots & t_{2,n} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & t_{n,n} \end{bmatrix}$

$TT^{*} = \begin{bmatrix} t_{1,1} & t_{1,2} & \cdots & t_{1,n} \\ 0 & t_{2,2} & \cdots & t_{2,n} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & t_{n,n} \end{bmatrix} \begin{bmatrix} \overline{t_{1,1}} & 0 & \cdots & 0 \\ \overline{t_{1,2}} & \overline{t_{2,2}} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ \overline{t_{1,n}} & \overline{t_{2,n}} & \cdots & \overline{t_{n,n}}\end{bmatrix}$

Let's compare $(1,1)$-entry
- $[T^{*}T]_{1,1}=|t_{1,1}|^{2}$
- $[TT^{*}]_{1,1}=|t_{1,1}|^{2}+|t_{1,2}|^{2} +\dots+|t_{1,n}|^{2}$

Since $[T^{*}T]_{1,1}=[TT^{*}]_{1,1}$, $t_{1,2}=t_{1,3}=\dots =t_{1,n}=0$
- Repeat this for $(2,2)$-entry, and so on
- Then $T$ is diagonal

## Finding spectral decomposition
1. Find Eigenvalues
2. Find eigenspaces
3. Construct an orthonormal basis of each eigenspaces
4. Place the eigenvalues along the diagonal of $D$, and the orthonormal bases of the corresponding eigenspaces as columns of $U$, in the same order
5. Double check by
	- $A=UDU^{*}$
	- $UU^{*}=I$

### Example 1)
Find a spectral decomposition of the matrix $A=\begin{bmatrix}1&1\\-1&1\end{bmatrix}$
$\Rightarrow\lambda=1\pm i$
- For $\lambda=1+i$, $\vec{v}=c(1,i)$
- For $\lambda=1-i$, $\vec{v}=c(1,-i)$

Construct orthogonal basis
- For $\lambda=1+i$, $\vec{v}=\frac{1}{\sqrt{ 2 }}(1,i)$
- For $\lambda=1-i$, $\vec{v}=\frac{1}{\sqrt{ 2 }}(1,-i)$

Then, 
$D=\begin{bmatrix}1+i&0\\0&1-i\end{bmatrix}$ and $U=\frac{1}{\sqrt{ 2 }}\begin{bmatrix}1&1\\i&-i\end{bmatrix}$


### Example 2)
Find a spectral decomposition of the matrix $A=\begin{bmatrix}1&2&2\\2&1&2\\2&2&1\end{bmatrix}$

$\lambda=-1,-1,5$
- For $\lambda=5$, $\vec{v}=c(1,1,1)$
- For $\lambda=-1$, $\vec{v}=c(1,-1,0)+d(1,0,-1)$

Construct orthonormal basis
- For $\lambda=5$, $\vec{v}=\frac{1}{\sqrt{3 }}(1,1,1)$
- For $\lambda=-1$, first we need to find 2 orthogonal vectors in the eigenspaces, then normalize each vectors
	- $(2,-1,-1)$ and $(0,1,-1)$ are orthogonal (add and substract two)
	- $\vec{v_{1}}=\frac{1}{\sqrt{ 6 }}(2,-1,-1)$
	- $\vec{v_{2}}=\frac{1}{\sqrt{ 2 }}(0,1,-1)$

Then, 
$D=\begin{bmatrix}5&0&0\\0&-1&0\\0&0&-1\end{bmatrix}$ and $U=\begin{bmatrix}\frac{1}{\sqrt{ 3 }}&\frac{2}{\sqrt{ 6 }}&0\\\frac{1}{\sqrt{ 3 }}&-\frac{1}{\sqrt{ 6 }}&\frac{1}{\sqrt{ 2 }}\\\frac{1}{\sqrt{ 3 }}&-\frac{1}{\sqrt{ 6 }}&-\frac{1}{\sqrt{ 2 }}\end{bmatrix}$


LA assignment 5
COMP arch review
Math Contest organize
ToC projecy
ToC reading & reading quiz
