# Linear Equation
A linear equation of variables $x_{1}, x_{2}\dots x_{n}$ is an equation of the form
$$a_{1}x_{1}+a_{2}x_{2}+\dots+a_{n}x_{n}=b$$
where $a_{i}'s$ and $b$ called coefficient, $b$ sometimes called constant

## Vector $\longleftrightarrow$ Linear Equations
Linear Equation represent flat or straight things
- $\mathbb{R}^{2}\implies$ Line
- $\mathbb{R}^{3}\implies$ Planes
- $\mathbb{R}^{4}\implies$ HyperPlane

# System of Linear Equations (Linear System)
Finite set of linear equations over the same variable
- Solution of the system is a vector that simultaneously satisfies all the linear equation
	- The solution set is the set of all solutions
	- In vector system, the solution of the system is a vector which starts at $(0,0)$ and ends at the intersaction of the system
- A linear system is **consistent** if the solution is non-empty, otherwise, it is **inconsistent**

## Equivalent System
Two linear systems are equivalent, if they have the same solution
- They are consistent solution since the solution exists

## Homogenous System
All constant terms are 0
- $[A\text{ | }0]$
- Always consistent because $\vec{0}$ is always a solution

# Matrices
An $n\times m$ matrix is an collection of elements in in $n$ rows and $m$ columns, enclosed in square brackets
- Vectors are $n\times1$ matrices

## Converting Linear System to Matrices
Each row correspond to an equation, each column corresponeds to a variable
- The entries are coefficient of the system

**Augmented Matrix**
- Contains the coefficients, the line, and the constant terms

**Coefficient Matrix**
- Augmented Matrix is without line and constant

# Elementary Row Operation
Ultimate Goal: Convert the matrix into Row Echelon Form(REF) or Row Reduced Echelon Form(R/REF)
1. Interchange two rows
2. Multiply a row by non-zero scalar
3. Add a multiple of a row to another 

# Row Echelon Form(REF)
1. All rows consisting entirely of zeros are below the non-zero rows
2. In each non-zero row, the first non-zero entry(Leading Entry) is to the left of any leading entries below
	- Any non-leading variable that is not constant can be checked by R/REF

**Ex)**
$$\begin{bmatrix}
x&y&z&w&|&c \\
1&2&2&3&|& 4 \\
0&0&5&6&|&7 \\
0&0&0&8&|&9
\end{bmatrix}$$

## Row Reduced Echelon Form(R/REF)
REF that satisfies following condition
- Each leading entry equals 1 and is the only non-zero entry in its column

**Ex)**
$$\begin{bmatrix}
1&0&0&0&|&3 \\
0&0&1&0&|&4 \\
0&0&0&1&|&7
\end{bmatrix}$$
$$\begin{bmatrix}
1&0&7&0&|&3 \\
0&1&3&0&|&4 \\
0&0&0&1&|&7
\end{bmatrix}$$
## Number of Solutions
System with no solution
- Matrix that one of the row is $\begin{bmatrix} 0&0&\dots&0&|&c \end{bmatrix}$ where $c\neq0$

**Ex)**
$$\begin{bmatrix}
1&0&0&0&|&3 \\
0&0&1&0&|&4 \\
0&0&0&0&|&7
\end{bmatrix}$$

Infinitely many solutions in R/REF
- There are variables that are not leading variable
- Call this free variable

**Ex)**
$$\begin{bmatrix}
x&y&z&w&|&c \\
1&0&0&0&|&3 \\
0&0&1&7&|&4 \\
0&0&0&0&|&7
\end{bmatrix}$$
- $w$ is free
### Free Variable
Non-zero entry that is not leading variable in R/REF
- System has infinitely many solutions
- Number of free variables represents the dimensionality of solutions

# Rank Theorem
Rank
- The number of non-zero rows in R/REF
## 1. Let $A$ be a coefficient matrix of reduced system of linear euqations of $m$ variables
- $\text{(Number of free variable)}=m-\text{rank}(A)$

## 2. If $[A\text{ | }0]$ has $n$ linear equations with $m$ variables, and $n<m$, then the system has infinitely many solutions
- More columns than rows

**Prove)**
Since $\text{rank}(A)$ is number of non-zero rows, $\text{rank}(A)\leq \text{\# row}=n$
- $-\text{rank}(A)\geq -n$

Then, 
$\text{(Number of free variable)}=m-\text{rank}(A)\geq m-n>0$
- Since free variable exists, there are infinitely many solutions

What if $m\leq n$?
- Can build examples that have many solutions or unique solutions

# Light Bulb Game
There are 5 lightbulbs and 5 switches
- Each swtich toggles the light bulb above and the ones immediately either side
- Turn off : 0 / Turn on : 1
	- Thus all entries for this game's metrix representation are from Binary
	- 0+1=1+0=1
	- 0+0=0
	- 1+1=0

![[Pasted image 20241222132653.png|600]]
Vector representations of each swtiches
- $A=[1,1,0,0,0]$
- $B=[1,1,1,0,0]$
- $C=[0,1,1,1,0]$
- $D=[0,0,1,1,1]$
- $E=[0,0,0,1,1]$

Vector representations of example states above
- $a) = [1,0,1,0,0]$
- $b)=[0,1,1,0,0]$
- $c)=[0,0,0,1,0]$

## Linear Combination Application
Given a starting state $\vec{s}$ and a target state $\vec{t}$ with vectors $\vec{x_{1}}, \vec{x_{2}}\dots\vec{x_{n}}$ , each represents button toggle rule, then $\vec{t}$ can be written as a linear combination of $\vec{s}\text{ \& }\vec{x_{1}}, \vec{x_{2}}\dots\vec{x_{n}}$
$$\vec{t}=c_{0}\vec{s}+c_{1}\vec{x_{1}}+c_{2}\vec{x_{2}}\dots c_{n}\vec{x_{n}}$$
Then, 
$$\vec{t}-c_{0}\vec{s}=c_{1}\vec{x_{1}}+c_{2}\vec{x_{2}}\dots c_{n}\vec{x_{n}}$$

Since the starting state is "on," we assign it the scalar 1, $c_{0}=1$
Then, since $-1=1$ in Binary,
$$\vec{t}+\vec{s}=c_{1}\vec{x_{1}}+c_{2}\vec{x_{2}}\dots c_{n}\vec{x_{n}}$$

## Metrix Representation
Using this, light bulb question above can be expressed as 
$$c_{1}[1,1,0,0,0]+c_{2}[1,1,1,0,0]+c_{3}[0,1,1,1,0]+c_{4}[0,0,1,1,1]+c_{5}[0,0,0,1,1]$$
$$=[c_{1},c_{1},0,0,0]+[c_{2},c_{2},c_{2},0,0]+[0,c_{3},c_{3},c_{3},0]+[0,0,c_{4},c_{4},c_{4}]+[0,0,0,c_{5},c_{5}]$$
$$=[t_{1}+s_{1}, t_{2}+s_{2}, t_{3}+s_{3}, t_{4}+s_{4}, t_{5}+s_{5}]$$
Therefore,
$$\begin{matrix}
c_{1}&+c_{2}&&&&=t_{1}+s_{1} \\
c_{1}&+c_{2}&+c_{3}&&&=t_{2}+s_{2} \\
&\quad c_{2}&+c_{3}&+c_{4}&&=t_{3}+s_{3} \\
&&\quad c_{3}&+c_{4}&+c_{5}&=t_{4}+s_{4} \\
&&&\quad c_{4}&+c_{5}&=t_{5}+t_{6}
\end{matrix}$$

Which can be expressed as augmented matrix
$$\begin{bmatrix}
1&1&0&0&0&|&t_{1}+s_{1} \\
1&1&1&0&0&|&t_{2}+s_{2} \\
0&1&1&1&0&|&t_{3}+s_{3} \\
0&0&1&1&1&|&t_{4}+s_{4} \\
0&0&0&1&1&|&t_{5}+s_{5}
\end{bmatrix}$$

# Span
In general, iven a list of vetors, $\vec{a_{1}},\vec{a_{2}}\dots \vec{a_{n}}$, and target vector $\vec{u}$, can $\vec{u}$ be written as a linear combination of $\vec{a_{i}}$'s?
- $\exists \text{ }c_{1},c_{2}\dots c_{n}$ such that $c_{1}\vec{a_{1}}+c_{2}\vec{a_{2}}\dots c_{n}\vec{a_{n}}=\vec{u}$ ?

A set of all Linear Combination of vectors $A=\{ \vec{a_{1}},\vec{a_{2}}\dots \vec{a_{n}} \}$ is called **Span** of $A$
- Denoted as $\text{span}(A)$ or $\text{span}(\{ \vec{a_{1}},\vec{a_{2}}\dots \vec{a_{n}} \})$
- If $\text{span}(A)=\mathbb{R}^{n}$ (i.e. any vectors in $\mathbb{R}^{n}$ can be expressed as a linear combination of vectors in $A$), $A$ is spanning set of $\mathbb{R}^{n}$ or $A$ spans $\mathbb{R}^{n}$
- A set of standard unit vectors are always spanning set of corresponding dimension

## Checking Span-ness
Taka an arbitrary vector in that dimension and findi scalars that satisfy the linear combination

# Linearly Dependent
Set of vector $\vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{k}}$ is linearly dependent if there exists scalars $c_{1},c_{2},\dots c_{k}$, *not all zero*, such that 
$$c_{1}\vec{v_{1}}+c_{2}\vec{v_{2}}\dots c_{k}\vec{v_{k}}=\vec{0}$$
- $\vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{k}}$ all live in a common subspace with dimension smaller than $k$
	- This indicates that there is at least 2 vectors are along the smae direction

In other word, this set is linearly dependent iff *at least one of the vectors canbe written as a linear combination of the others*
- If there is some $\vec{v_{j}}$ such that $\vec{v_{j}}=c_{1}\vec{v_{1}}+c_{2}\vec{v_{2}}\dots c_{k}\vec{v_{k}}$, then $\vec{v_{j}}-c_{1}\vec{v_{1}}+c_{2}\vec{v_{2}}\dots c_{k}\vec{v_{k}}=\vec{0}$

**How to check?**
- There is one vector a scalar multiplication of another vector in the set
- The set contains $\vec{0}$
- Otherwise, try to find a scalars not all zero, such that $c_{1}\vec{v_{1}}+c_{2}\vec{v_{2}}\dots c_{k}\vec{v_{k}}=\vec{0}$

# Linear Independent
If the only way to have 
$$c_{1}\vec{v_{1}}+c_{2}\vec{v_{2}}\dots c_{k}\vec{v_{k}}=\vec{0}$$
is iff all coefficient is 0
- We have to show that there is no other solution
- All $c_{i}$'s has to be zero

How to solve
- Change the linear combination to augmented matrix and make R/REF and if the unique solution lead that all coefficients being zero
- If there is free variable, then there are many solutions possible, thus not Independent

# Theorems about Linear Independence
1. Vectors $\vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{k}}$ are linearly dependent iff at least one vector can be expressed as a linear combination of the others
2. Let $\vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{m}}$ be column vectors in $\mathbb{R}^{n}$ and let $A$ be the $n\times m$ matrix made by sticking all the column vectors. Then $\vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{m}}$ is linearly dependent iff $[A\text{ | }0]$ has non-trivial solution
3. Let $\vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{m}}$ be row vectors in $\mathbb{R}^{n}$. Let $A$ be $m\times n$ matrix that sticks all $\vec{v_{i}}$'s, then $\vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{m}}$ is linearly dependent iff rank($A$)<$m$
4. Any set of $m$ column vectors in $\mathbb{R}^{n}$, it is linearly dependent if $m>n$
	- Since there would be at least one free variable
	- $m\leq n$ doesn't mean linear independence

