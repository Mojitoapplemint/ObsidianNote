# Field
A set on which we can add, subtract, multiply and divide according to the usual laws of arithmetic
- Denoted as $\mathbb{F}$

**Ex)** $\mathbb{R}, \mathbb{C},\mathbb{Z}_{p}$ ($p$ is prime), etc

## Properties
1. 0 is in the field
2. 1 is in the field
3. Associativity
4. Commutativity

# Addition and Scalar Multiplication
Let $\mathcal{V}$ be a set and let $\mathbb{F}$ be a field. Let $\vec{v}, \vec{w}\in \mathcal{V}$ and $c\in\mathbb{F}$ and suppose we have defined two operations called addition and scalar multiplication on $\mathcal{V}$.

We write the addition of $\vec{v}$ and $\vec{w}$ as $\vec{v}+\vec{w}$, and the scalar multiplication of $c$ and $\vec{v}$ as $c\vec{v}$

# Vector Space
If the following ten conditions hold for all $\vec{v}, \vec{w}, \vec{x}\in\mathcal{V}$ and all $c,d\in \mathbb{F}$, then $\mathcal{V}$ is called **vector space** and its elements are called **vectors**
1. $\vec{v}+\vec{w}\in\mathcal{V}$
2. $\vec{v}+\vec{w}=\vec{w}+\vec{v}$
3. $(\vec{v}+\vec{w})+\vec{x}=\vec{v}+(\vec{w}+\vec{x})$
4. There exists a zero vector $\vec{0}\in\mathcal{V}$ such that $\vec{v}+\vec{0}=\vec{v}$
5. There exists a vector $-\vec{v}$ such that $\vec{v}+(-\vec{v})=\vec{0}$
6. $c\vec{v}\in\mathcal{V}$
7. $c(\vec{v}+\vec{w})=c\vec{v}+c\vec{w}$
8. $(c+d)\vec{v}=c\vec{v}+d\vec{v}$
9. $c(d\vec{v})=(cd)\vec{v}$
10. $1\vec{v}=\vec{v}$

**Note)** At intro linear algebra, $\mathbb{F}=\mathbb{R}$

**Ex)** $\mathbb{R}^{n}$

**Ex)** $\mathcal{F}$, the set of all functions $f:\mathbb{R}\to\mathbb{R}$
4. Is there $\vec{0}\in\mathcal{F}$ with $\forall \text{ }f\in\mathcal{F}, f+\vec{0}=f$
- Let $\vec{0}$ be $0(x)=0$

5. Is there $-f\in\mathcal{F}$ for any $f\in\mathcal{F}$ such that $f+(-f)=\vec{0}$
- Define $(-f)(x)=-f(x)$

**Ex)** $\mathcal{M}_{m,n}(\mathbb{F})$, the set of all $m\times n$ matrices with entries from $\mathbb{F}$


# Subspace
If $\mathcal{V}$ is a vector space and $\mathcal{S}\subseteq\mathcal{V}$, then $\mathcal{S}$ is a subspace of $\mathcal{V}$ if $\mathcal{S}$ is itself a vector space with the same addition and scalar multiplication as $\mathcal{V}$

## Theorem 1.1 Determining if a Set is a Subspace
Let $\mathcal{V}$ be a vector space and let $\mathcal{S}\subseteq\mathcal{V}$ be non-empty. Then $\mathcal{S}$ is a subspace iff the following two conditions hold for all $\vec{v}, \vec{w}\in\mathcal{S}$ and all $c\in\mathbb{F}$
1. $\vec{v}+ \vec{w}\in\mathcal{S}$
2. $c\vec{v}\in\mathcal{S}$

Where addition and scalar multiplication is from $\mathcal{V}$

"If this two hold, then rest 8 hold automatically"

**Proof)**
i) $(\longrightarrow)$ Direction
Let $\mathcal{S}$ is subspace of $\mathcal{V}$. Then $\mathcal{S}$ is also a vector space by definition of subspace 
- Then by axiom 1), $\vec{v}+\vec{w}\in\mathcal{S}$
- By axiom 6), $c\vec{v}\in\mathcal{S}$

ii) $(\longleftarrow)$ Direction
Let $\mathcal{S}$ is a set that two conditions above hold for all elements in it.
- Let $\vec{v}, \vec{w}, \vec{x}\in\mathcal{S}$

We need to prove that $\mathcal{S}$ is a vector space with the same addition and scalar multiplication as $\mathcal{V}$ 
- Let's prove all 10 axioms for vector 

By condition 1), $\vec{v}+\vec{w}\in\mathcal{S}$, thus axiom 1 hold

By condition 2), $c\vec{v}\in\mathcal{S}$, thus axiom 6 hold

For axiom 2,3,7,8,9,10. Since $\mathcal{V}$ is a vector space, axiom 2,3,7,8,9,10 hold for $\mathcal{V}$. Since if $\vec{v}, \vec{w}, \vec{x}\in\mathcal{S}$, then $\vec{v}, \vec{w}, \vec{x}\in\mathcal{V}$, axioms hold for $\mathcal{S}$ as well

For axiom 5, since $\mathcal{V}$ is a vector space, $\exists \text{ }\vec{-v\in\mathcal{V}}$ such that $\forall \text{ }-\vec{v}\in\mathcal{V}$, $\vec{v}+(-\vec{v})=\vec{0}$
- Since $\forall \text{ }\vec{w}\in\mathcal{S}, \vec{w}\in \mathcal{V}$, thus $\exists \text{ }-\vec{w}\in\mathcal{V}$
- Then by condition 2), $-\vec{w}\in\mathcal{S}$

For axiom 4, from axiom 5), $\forall \text{ }\vec{v}\in\mathcal{S}$, $\exists \text{ }-\vec{v}\in\mathcal{S}$ such that $\vec{v}+(-\vec{v})=\vec{0}$
- And by condition 1) , $\vec{0}\in\mathcal{S}$

## Example) Is $\mathcal{P}^{p}$, the set of real-valued polynomials of degree at most $p$, a subspace of $\mathcal{F}$?
Yes, sum of polynomials is polynomial and scalar multiplication of polynomial is polynomial

## Example) Is the set of $2\times2$ matrices with determinant of 0 a subspace of $\mathcal{M}_{2}$
Define $\mathcal{M}_{n}(\mathbb{F})$ a set of all $n\times n$ matrices where all entries came from $\mathbb{F}$
- No

Counter-example)
$\begin{vmatrix}1&0\\0&0\end{vmatrix}=0$ and $\begin{vmatrix}0&0\\0&1\end{vmatrix}=0$

But $\det(\begin{bmatrix}1&0\\0&0\end{bmatrix}+\begin{bmatrix}0&0\\0&1\end{bmatrix})=\det(\begin{bmatrix}1&0\\0&1\end{bmatrix})=1\neq{0}$

# Linear Combination
Let $\mathcal{V}$ a vector space over the field $\mathbb{F}$. Let $\vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{k}}\in\mathcal{V}$ and let $c_{1}, c_{2}\dots c_{n}\in\mathbb{F}$. Then every vector of the form
$$ c_{1}\vec{v_{1}}+c_{2}\vec{v_{2}}+\dots+c_{k}\vec{v_{k}}$$
- $k$ has to be finite
# Spans
Let $\mathcal{V}$ be a vector space and let $B\subseteq\mathcal{V}$ be a set of vectors. Then the span of $B$, denoted as $\text{span}(B)$, is the set of all **finite** linear combination of vectors from $B$
- If $\text{span}(B)=\mathcal{V}$, then $\mathcal{V}$ is said to be spanned by $B$, or $B$ spans $\mathcal{V}$

**Ex)**
$\mathcal{P}^{p}=\text{span}( 1,x,x^{2}\dots x^{p})$

**Ex)**
Is $e^{x}\in \text{span}(1,x,x^{2}\dots)$ ?
- By Taylor Series, it seems that $e^{x}$ can be written as linear combination, but actually this statement is not true
- Even though it is okay to put infinite sum in $\text{span}$ operation, a vector must be able to written as **finite** linear combination
- Intuitively, all element in the spanning set would be polynomial whose derivative eventually reach zero. However, derivative of $e^{x}$ never reaches zero

## Theorem 1.2 Spans are Subspace
Let $\mathcal{V}$ be a vector space and let $B\subseteq\mathcal{V}$. Then $\text{span}(B)$ is a subspace of $\mathcal{V}$

**Proof)**
By Theorem 1.1, we just need to prove two properties

Let $\vec{v}, \vec{w}\in \text{span}(B)$

i) Prove $\vec{v}+\vec{w}\in \text{span}(B)$
Since $\vec{v}, \vec{w}\in \text{span}(B)$, there are some scalars $c_{i}$'s and $d_{i}$'s such that
- $\vec{v}=c_{1}\vec{b_{1}}+c_{2}\vec{b_{2}}\dots c_{k}\vec{b_{k}}$
- $\vec{w}=d_{1}\vec{b_{1}}+d_{2}\vec{b_{2}}\dots d_{k}\vec{b_{k}}$

Then, $\vec{v}+\vec{w}=c_{1}\vec{b_{1}}+c_{2}\vec{b_{2}}\dots c_{k}\vec{b_{k}}+d_{1}\vec{b_{1}}+d_{2}\vec{b_{2}}\dots d_{k}\vec{b_{k}}$
		   $=(c_{1}+d_{1})\vec{b_{1}}+(c_{2}+d_{2})\vec{b_{2}}\dots (c_{k}+d_{k})\vec{b_{k}}$
- Since $c_{i}+d_{i}$'s are all valid scalar, $\vec{v}+\vec{w}\in \text{span}(B)$

ii) Prove $c\vec{v}\in \text{span}(B)$
Let $c\in\mathbb{F}$
Since $\vec{v}\in \text{span}(B)$, there are some scalars $c_{i}$'s such that
- $\vec{v}=c_{1}\vec{b_{1}}+c_{2}\vec{b_{2}}\dots c_{k}\vec{b_{k}}$

Then, $c\vec{v}=cc_{1}\vec{b_{1}}+cc_{2}\vec{b_{2}}\dots cc_{k}\vec{b_{k}}$
- Since $c\cdot c_{i}$'s are all valid scalar, $c\vec{v}\in \text{span}(B)$

# Linear Dependence and Independence
Let $\mathcal{V}$ a vector space over the field $\mathbb{F}$ and let $B\subseteq\mathcal{V}$ be a set of vectors. Then, $B$ is **linearly dependent** if there exists scalars $c_{1}, c_{2}\dots c_{n}\in\mathbb{F}$, at least one of which is not zero, and vectors $\vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{k}}\in B$ such that
$$ c_{1}\vec{v_{1}}+c_{2}\vec{v_{2}}+\dots+c_{k}\vec{v_{k}}=\vec{0}$$

If $B$ is not dependent, then it is called **linearly independent**
- All scalar must be zero to satisfy above

$B$ is linearly dependent iff there exists a vector in $B$ that is linear combination of rest of vectors in $B$

**Ex)**
Is the set of functions $\{ \sin^{2}(x), \cos^{2}(x), \cos(2x) \}\subset\mathcal{F}$ linearly dependent or independent?

Check
- Does $c_{1}\sin^{2}(x)+ c_{2}\cos^{2}(x)+c_{3} \cos(2x)=0$ implies $c_{1}=c_{2}=c_{3}=0$?

From triangualr identity, $\cos(2x)=\cos^{2}(x)-\sin^{2}(x)$
- Then, $\sin^{2}(x)-\cos^{2}(x)+\cos(2x)=0$

Since scalars are not all zero, this set is linearly dependent

# Bases
A basis of a vector space $\mathcal{V}$ is a set of vectors in $\mathcal{V}$ that
1. Spans $\mathcal{V}$
2. Is linearly independent

$\implies$ Big enough to represent all vectors in the set but also small enough not to have any redundancies

$\implies$ Each basis represents the *direction that we can go in that vector space*

## Standard Basis of $\mathbb{R}^{n}$
Let $e_{i}$ be the vector in $\mathbb{R}^{n}$ with a $1$ in its $i^{th}$ entry and zeros else where. Then $\{ e_{1},e_{2},\dots e_{n} \}$ is a standard basis of $\mathbb{R}^{n}$

## Standard Basis of $\mathcal{M}_{m,n}$
Let $E_{i,j}\in\mathcal{M}_{m,n}$ be the matrix with a $1$ in its $(i,j)$ entry and zeros elsewhere. Then, $\{ E_{1,1}, E_{1,2}\dots E_{m,n} \}$ is a standard basis of $\mathcal{M}_{m,n}$


## Standard Basis of $\mathcal{P}^{p}$
Set of polynomials $\{ 1,x,x^{2}\dots x^{p} \}$ is a standard basis of $\mathcal{P}^{p}$

# Coordinate Vectors
## Theorem 2.1: Uniqueness of Linear Combination
Let $\mathcal{V}$ be a vector space and let $B$ be a basis for $\mathcal{V}$. Then for every $\vec{v}\in\mathcal{V}$, there is only one way to write $\vec{v}$ as a linear combination of the basis vectors in $B$

**Proof)**
Suppose there is scalar $c_{i}$'s and $d_{i}$'s such that 
- $\vec{v}=c_{1}\vec{v_{1}}+c_{2}\vec{v_{2}}\dots c_{n}\vec{v_{n}}$
- $\vec{v}=d_{1}\vec{v_{1}}+d_{2}\vec{v_{2}}\dots d_{n}\vec{v_{n}}$

Consider $\vec{v}-\vec{v}$
	$=c_{1}\vec{v_{1}}+c_{2}\vec{v_{2}}\dots c_{n}\vec{v_{n}}-d_{1}\vec{v_{1}}+d_{2}\vec{v_{2}}\dots d_{n}\vec{v_{n}}$
	$=(c_{1}-d_{1})\vec{v_{1}}+(c_{2}-d_{2})\vec{v_{2}}\dots (c_{n}-d_{n})\vec{v_{n}}=\vec{0}$

By linear independence of $B$, $c_{i}-d_{i}$ must be 0
- Therefore, $c_{i}=d_{i}$

## Coordinate Vectors
Suppose $\mathcal{V}$ is a vector sapce over a field $\mathbb{F}$ with a finite ordered basis $B=\{ \vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{n}} \}$ and $\vec{v}\in\mathcal{V}$. Then the unique scalars $c_{1},c_{2},\dots c_{n}\in\mathbb{F}$ for which 
$$\vec{v}=c_{1}\vec{v_{1}}+c_{2}\vec{v_{2}}\dots c_{n}\vec{v_{n}}$$
are called Coordinates of $\vec{v}$ with respect to $B$, and the vector
$$[\vec{v}]_{B}=(c_{1},c_{2},\dots c_{n})$$
is called Coordinate vectors of $\vec{v}$ with respect to $B$

**Note)** The *order* in which the basis vectors appear in $B$ affects the order of the entries in the coordinate vector

**Ex)** Find the coordinate vector of $p(x)=1-x+3x^{2}$ with respect to the basis $B=\{ x^{2},x,1 \}$
- $[p]_{B}=(3,-1,4)$
## Arithmetic of Coordinate Vectors
Let $\vec{v}, \vec{w}\in\mathcal{V}$ and $c\in\mathbb{F}$
- $[\vec{v}+\vec{w}]_{B}=[\vec{v}]_{B}+[\vec{w}]_{B}$
- $[c\vec{v}]_{B}=c[\vec{v}]_{B}$

# Dimension of Vector Space

## Theorem 2.2 Linearly Independent Set versus Spanning Set
Let $\mathcal{V}$ be a vector space with basis $B$ of size $n$. Then
1. Any set of more than $n$ vectors in $\mathcal{V}$ must be linearly dependent
2. Any set of fewer than $n$ vectors cannot span $\mathcal{V}$

**Proof)**
i) Any set of more than $n$ vectors in $\mathcal{V}$ must be linearly dependent
Suppose for $m>n$ vectors, which we call $\vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{m}}$ we want to solve $c_{1}\vec{v_{1}}+c_{2} \vec{v_{2}}\dots +c_{m}\vec{v_{m}}=\vec{0}$. 

This is the same as $[c_{1}\vec{v_{1}}+c_{2} \vec{v_{2}}\dots +c_{m}\vec{v_{m}}]_{B}=[\vec{0}]_{B}=\vec{0}$

However, direct calculation shows that $[c_{1}\vec{v_{1}}+c_{2} \vec{v_{2}}\dots +c_{m}\vec{v_{m}}]_{B}=c_{1}[\vec{v_{1}}]_{B}+c_{2} [\vec{v_{2}}]_{B}\dots +c_{m}[\vec{v_{m}}]_{B}$
- This can be written as matrix multiplication : $\big[[\vec{v_{1}}]_{B}, [\vec{v_{2}}]_{B}\dots ,[\vec{v_{m}}]_{B}\big]\cdot \begin{bmatrix}c_{1}\\c_{2}\\ \vdots\\c_{m}\end{bmatrix}$
	- Note that $\big[[\vec{v_{1}}]_{B}, [\vec{v_{2}}]_{B}\dots ,[\vec{v_{m}}]_{B}\big]$ is $n\times m$ matrix

Therefore, $\big[[\vec{v_{1}}]_{B}, [\vec{v_{2}}]_{B}\dots ,[\vec{v_{m}}]_{B}\big]\cdot \begin{bmatrix}c_{1}\\c_{2}\\ \vdots\\c_{m}\end{bmatrix}=\vec{0}$

Since this is a homogenous linear system with $m$ variables and $n$ equations and $m>n$, there is infinitely many solution
- Therefore, $\{ \vec{v_{1}}, \vec{v_{2}}\dots \vec{v_{m}} \}$ is linearly dependent

ii) Any set of fewer than $n$ vectors cannot span $\mathcal{V}$

**Exercise)**
## Corollary 2.3: Uniqueness of Size of Bases
Let $\mathcal{V}$ be a vector space that has a basis consisting of $n$ vectors. Then every basis of $\mathcal{V}$ has exactly $n$ vectors

**Proof)**
Let $c$ is arbitrary basis of $\mathcal{V}$ consisting of $m$ vectors
- If $m>n$, then it is not linearly independent, thus it cannot be a basis
- If $m<n$, then it cannot span $\mathcal{V}$, thus it cannot be a basis

Therefore, $m=n$

## Dimension of a Vector Space
A vector space $\mathcal{V}$ is called
- **Finite-Dimensional :** If it has a finite basis, and its dimension, denoted by $\text{dim}(\mathcal{V})$, is the number of vectors in one its bases
- **Infinite-Dimensional :** If it has no finite basis, and we way that $\text{dim}(\mathcal{V})=\infty$

