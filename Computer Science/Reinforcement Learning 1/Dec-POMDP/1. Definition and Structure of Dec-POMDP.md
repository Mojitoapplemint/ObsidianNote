# Definition
Dec-POMDP is defined as tuple $\mathcal{M}=\langle\mathbb{D}, \mathbb{S, A}, T, \mathbb{O}, O, R, h, b_{0}\rangle$
- $\mathbb{D}=\{ 1,2,\dots n \}$ is the set of $n$ agents
- $\mathbb{S}$ is a (finite) set of states
- $\mathbb{A}$ is the set of joint actions
- $T$ is the transition probability function
- $\mathbb{O}$ is the set of joint observations
- $O$ is the obervation probability function
- $R$ is the immediate reward function
- $h$ is the horizon of the problem
	- The number of time steps during agents interacting with their environment
- $b_{0}=\Delta(\mathbb{S})$ is the initial state distribution at time $t=0$

## Additional Definition
$$\mathbb{A}=\times_{i\in \mathbb{D}}\mathbb{A}_{i}$$
- Where $\mathbb{A}_{i}$ is the set of actions available to agent $i$

Suppose each agent $i$ takes an action at time step $t$, $a_{i,t}$ , then tuple of all actions made by agents 