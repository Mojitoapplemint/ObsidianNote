Parallelism through pipelining instructions

# Abstract
Deeper Pipeline to overlap more instruction
- If single task takes longer than others, then divide that into subtasks and consider each subtask as another stage of parallelism
	- To get full speed up, we need to rebalance the remaining steps, aiming for identical durations
- Less work per stage $\Rightarrow$ Shorter clock cycle $\Rightarrow$ GHZ goes up

Multiple Issues
- Replicate internal components of the computer
	- Start multiple instructions per clock cycle
- This allows CPI to be less than 1
	- So use instruction per cycle(IPC)

# Multiple-issue Datapath
Two ways to implement multiple issue
- Division of work between compiler and hardware

## Static Multiple Issue
Compiler packages instructions into issue slots
- Compiler will also handles data and control hazards statistically

## Dynamic Multiple Issue
Packaging instruction is done by processor
- It examines instruction stream and chooses instructions to issue each cycle
- Compiler can help by reordering instructions

CPU resolves hazards at runtime
- Requires extra hardware

# Speculation
An approach that allows the compiler or the processor to "guess" about properties of an instruction, to enable execution to begin for other instructions that may depend on the speculated instruction
- Start operation ASAP
- Check whether guess was right
	- If so, complete the operation
	- If not, roll-back and do the right thing

## Compiler vs Hardware Speculation
Compiler 
- Can reorder instructions, moving an instruction across a branch or a load across a store
- Can include "fix-up" instructions to recover from incorrect guess

Processor can do the same transformation at runtime
- Buffer results until it determines they are actually needed
- Flush buffers on incorrect speculation

# Static Multiple Issue
Compiler groups instructions into “issue packets”
- Group of instructions that there are *no dependencies with each other*
- Determined by pipeline resources required
- e.g. an add and a load instruction

Think of an issue packet as a very long instruction
- Specifies multiple concurrent operations
- Also called Very Long Instruction Word (VLIW)

## Scheduling
Compiler must remove some/all hazards
- Reorder instructions into issue packets 
- No dependencies within a packet
- Possibly some dependencies between packets 
	- Varies between ISAs; compiler must know! 
- Pad with `nop` (no-operation) if necessary

# RISC-V with Static Dual Issue
Two issue packets
- ALU/branch instruction & Load/store instruction
- 64bit aligned
	- ALU/branch, then load/store
	- Pad an unused instruction with `nop`
- Need more hardware
	- Extra ports in register file
	- Extra adder for address calculation(Structual hazard occur without it)

# Loop Unrolling
Replicate loop body to expose more parallelism
- Reduces loop-control overhead
Use different registers per replication

# Dynamic Multiple Issue (Superscalar Processors)
Instructions issue in order, and the processor decides whether zero, one, or more instructions can issue in a given clock cycle
- Stills beneficial to let the compiler to try to schedule instructions to move dependences apart

The code is guaranteed by the hardware to execute correctly
- Compiled code will always tun correctly independent of the issue rate or pipeline structure of the processor

## Dynamic Pipeline Scheduling
Chooses which instructions to execure in a given clock cycle while trying to acoid hazards and stalls
![[Pasted image 20250407032955.png|350]]
In such processors, the pipeline is divided into three major units
1. Instruction fetch and issue unit
2. Multiple functional units
3. Commit unit

Steps
1. As instructions are fetched and decoded by fetch and issue unit, these are sent to corresponding functional unit for execution
	- Issues instruction in order to allow dependences to be tracked
2. Each funtional unit has buffers, called reservation stations, which hold the operands and the operations
	- As soon as the buffer contains all its operands and the functional unit is ready to execure, the result is calculated
	- The result is sent to any reservation stations wating for this as well as to the commit unit
	- **Out-of-Order Execution**
		- Instructions can be executed in a different order than they were fetched but some order that preserves the data flow order
3. Reorder Buffer in commit unit will store the results until it is safe to put those to register file, or store in memory
	- Reorder buffer is also used to supply operands, similar to the forwarding logic
	- Once the result is committed to the register file, it can be fetched directly from there
	- In-Order Commit
		- Commit unit is required to write results to register and memory in program fetch order

## Hardware-based Speculation
Predicting the direction of a branch
- Processor can continue to fetch and execure instructions along the predicted path
- Do not commit until the branch outcome is determined

Speculation on load address
- Avoid load and cache miss delay
	- Predict the effective address
	- Predict loaded value
	- Load before completing outstanding stores
- Don’t commit load until speculation cleared

## Why not just let the compiler schedule code?
1. Not all stalls are predicable
	- e.g., cache misses
2. Can’t always schedule around branches
3. Branch outcome not known at compile time
4. Different implementations of an ISA have different latencies and hazards

