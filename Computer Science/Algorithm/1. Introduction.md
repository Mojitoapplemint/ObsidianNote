 # What is Algorithm?
Set of **well-defined** rules for solving computational problems
- Well-defined means you can't bend or change it
- Consist of basic operations: Addition and Simple Multiplication(between two 1digit numbers)

# 3 Principles for the Analysis of Algorithm
## Worst-Case Analysis
The performance of the algorithm varies depend on how good the input is
- But is there any input that can bend the running time?
- i.e. Is running time valid for all input?
	- If it can, assuption might be too vague or running time is wrong

## Big-Picture Analysis
We don't worry about small constant factors or lower-order terms in running time bounds
- We look at big picture
- To determine which algorithms tend to be faster

## Asymptotic Analysis
Focuses on the rate of growth of running time of the algorithm as the input size $n$ large
- As $n$ goes *infinitely large*, which algorithm is faster?

**Fast Algorithm**
- Algorithm whose worst-case running time grows slowly with input size