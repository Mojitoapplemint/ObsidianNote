# Definitions
**Alphabet**
- $\sum$
- Is a finite non-empty set of symbols

**Binary Code**
- A sequence of bits (0s and 1s)
- Binary code for an alphabet is a way of writing each of its symbols as a distinct binary string

**Fixed-Length Binary Code**
- Each symbol uses the same number of bits to be encoded

**Variable-Length Code**
- Each symbol may use different number of bits to be encoded

# Variable-Length vs Fixed-Length
Even though variable-length uses less bits, it can cause confusion while encoding

**Ex)**

| Symbol | Variable | Fixed |
| ------ | -------- | ----- |
| A      | 0        | 00    |
| B      | 01       | 01    |
| C      | 10       | 10    |
| D      | 1        | 11    |
-> Variable-length can't distinguish AAD and AB, since both are encoded as 001

# Prefix-free Code
**Fixed-length codes can be too long
Variable-length codes are unclear**

Prefix-free code is variable-length code that none of the elements are not a prefix of other element

| Symbol | Encoding |
| ------ | -------- |
| A      | 0        |
| B      | 10       |
| C      | 110      |
| D      | 111      |
-> Becase 0 is used to encode A, the encodings of the other three symbols must start with 1

Variable-length codes can be more efficient than fixed-length *if some symbols of the alphabet occur much more frequently than others*


## Performance Comparison with different frequencies of uses
Prefix-free Variable length

| Symbol | Frequency | Encoding | bits |
| ------ | --------- | -------- | ---- |
| A      | 60%       | 0        | 1    |
| B      | 25%       | 10       | 2    |
| C      | 10%       | 110      | 3    |
| D      | 5%        | 111      | 3    |
- Average number of bits per symbol
	-> $1\cdot 0.6+2\cdot 0.25+3\cdot 0.1+3\cdot 0.05=1.55$

Fixed-legngth
- Average number of bits per symbol
	-> 2

Prefix-free is 22.5% more efficient

# Codes to Binary Tree
**Fixed-Length**
![[Pasted image 20241014222329.png|600]]

**Variable-Length**
![[Pasted image 20241014222404.png|600]]

**Prefix-Free**
![[Pasted image 20241014222423.png|600]]


## Proposition
For every binary code, the encoded length in bits of a symbol $a\in \sum$ equals the *depth of the node* with a label $a$ in the corresponding Binary Tree
- Depth: Number of edges on the path to it from the root

## Bottom up Approach
Start with $n$ nodes and build up a tree with successive mergers
![[Pasted image 20241014222939.png|400]]

![[Pasted image 20241014223001.png|400]]

![[Pasted image 20241014223017.png|400]]

![[Pasted image 20241014223037.png|400]]

# Forest
Huffman's greedy algorithm maintains a forest
- Forest: Collection of binary trees
- The leaves of the trees are in 1-1 correspondence with the symbols in $\sum$

Each iteration chooses two trees and merges them by making their roots the left and right children
- The algorithm stops when only one tree remains

# Huffman's Greedy Criterion
Merge the pair of trees that causes the **minimum-possible increase** in the average leaf depth
- First iteration merges the nodes with the smallest frequency
- The second merge is with the trees that have the *smallest sums of frequencies*
- And so on

## Example)

| Symbol | Frequency |     | Symbol | Frequency |
| ------ | --------- | --- | ------ | --------- |
| A      | 3         |     | B      | 2         |
| B      | 2         |     | E      | 2         |
| C      | 6         |     | A      | 3         |
| D      | 8         |     | C      | 6         |
| E      | 2         |     | F      | 6         |
| F      | 6         |     | D      | 8         |

![[Pasted image 20241014223832.png|300]]
![[Pasted image 20241014223841.png|300]]
![[Pasted image 20241014223918.png|300]]
![[Pasted image 20241014223938.png|300]]
![[Pasted image 20241014223958.png|300]]

Thus, the answer is
![[Pasted image 20241014224120.png|400]]











