# Definition
Learning what to do -how to map situations to actions- so as *to maximize the numerical reward signal*
- **Trial-and-Error Search:** The learner is not told which actions to take, but discover which actions yield the most reward by trying them
- **Delayed Rewards:** Actions may affect not onlt the immediate rewards but also next situation and, through that, all subsequent rewards

## Markov Decision Process
Learning agent must 
1) Be able to *sense the state of its environment* to some extent
2) Be able to *take actions* that affect the state
3) *Have a goal* or goals relating to the state of environment

Will discuss deeply in Chapter 3

## Neither supervised nor unsupervised
In interactive problems, it is often impracical to obtain examples of desired behaviour that are both correvt and representative of all the situations in which the agent has to act
- Supervised Learning is not suitable

Since Reinforcement Learning is trying to maximize a reward signal instead of trying to find hidden structure, it is not unsupervised as well.

# Elements
## Policy
Agent's way of behaving at a given time
- Mapping from perceived states of the environment to actions to be taken when in those states
- Alone is sufficient to determine behaviour
	- Specifying probabilities for each action, etc)

## Reward Signal
Defines the goal of the problem
- Environment sendsa single number, reward, to the reinforcement learning agent
- Define good or bad
- Agent's objective is to maximize the total reward

## Value Function
Long-Term desirability of states after taking into account the states that are likely to follow
- Total amount of reward an agent can expect to accumulate over the future
- Estimates values only to acheive more reward
- Actions choices are made based on value judgement
	- Seek actions led to highest value, not highest rewards for greatest reward over the long run

## Model (Optional)
Something that mimics/represents the behaviour of the environment
- Allows inferences to be made about how the environment will behave
- Used for planning: predict the resultant next state and reward

Model-Based Methods
- Methods for solving reinforcement learning problems that use models and planning

Model-Free Methods
- Opposing Model-Based Methods

# Four Fundamental Concepts
## Agents
- The actor operating within the environment, it is usually governed by a policy

## Environment
- The world in which the agent can operate in

## Action
- The agent can do something within environment known as an action

## Reward and Observation
- In return the agent receives a reward and a view of what the environment looks like after acting on it

# Limitation and Scope
Relies heavily on the concept of state
- State: 
	- Imformally means signal conveying to the agent some sense of "how the environment is" at a particular time
	- Whatever information is available to the agent about its environment
	- 

