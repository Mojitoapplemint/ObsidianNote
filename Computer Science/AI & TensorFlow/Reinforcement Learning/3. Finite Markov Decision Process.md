Classical formalization of sequential decision making, where actions influence not just immediate rewards, but also subsequent situations, or states, and through those future rewards
- Involve delayed reward and need to tradeoff immediate and delayed reward
- Estimate the value $q_{*}(s,a)$ of each action a in each state $s$, or we estimate the value $v_{*}(s)$ of each state given optimal action selections

# The Agent-Environment Interface

![[Pasted image 20240927105631.png|500]]

Agent Selecting actions and the environment responding to these actions and presenting new situations to the agent
- Agent
	- The learner and decision maker
- Environment
	- The thing agent interacts with, comprising everything outside the it
	- Gives rewards, special numerical values that agent seeks to maximize over time


